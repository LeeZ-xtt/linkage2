"""
å¯è§†åŒ–å·¥å…·æ¨¡å—
"""

import os
import matplotlib
matplotlib.use('Agg', force=True)
import matplotlib.pyplot as plt
import numpy as np
import torch
import matplotlib.font_manager as fm
from matplotlib.font_manager import FontProperties
from sklearn.manifold import TSNE
from typing import Optional, List, Dict, Tuple, Union

_cjk_candidates = [
    'Microsoft YaHei',
    'SimHei',
    'Noto Sans CJK SC',
    'Source Han Sans SC',
    'PingFang SC',
    'WenQuanYi Zen Hei',
    'Arial Unicode MS'
]
_available_fonts = {f.name for f in fm.fontManager.ttflist}
_selected_font = next((n for n in _cjk_candidates if n in _available_fonts), 'DejaVu Sans')
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = [_selected_font, 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def _is_interactive_backend() -> bool:
    try:
        backend = matplotlib.get_backend()
    except Exception:
        return False
    interactive_backends = {"TkAgg", "Qt5Agg", "QtAgg", "WebAgg", "MacOSX", "nbAgg"}
    return backend in interactive_backends


def _safe_filename(title: str) -> str:
    name = "".join(c if c.isalnum() or c in "-_." else "_" for c in title.strip())
    return name or "figure"


def _default_save_path(title: str) -> str:
    out_dir = os.path.join(".", "figures")
    os.makedirs(out_dir, exist_ok=True)
    return os.path.join(out_dir, f"{_safe_filename(title)}.png")


def _finalize_figure(fig, title: str, save_path: str | None = None) -> None:
    if save_path is None and not _is_interactive_backend():
        save_path = _default_save_path(title)
    if save_path is not None:
        fig.savefig(save_path, dpi=300, bbox_inches='tight')
    if _is_interactive_backend() and save_path is None:
        plt.show()
    plt.close(fig)


def visualize_alpha_weights(alpha_weights, layer_names, title="Layer Weights Visualization", save_path=None):
    """
    å¯è§†åŒ–å±‚æƒé‡Î±
    
    Args:
        alpha_weights: æƒé‡æ•°ç»„
        layer_names: å±‚åç§°åˆ—è¡¨
        title: å›¾è¡¨æ ‡é¢˜
    """
    # å¦‚æœalpha_weightsæ˜¯torch.Tensorï¼Œåˆ™è½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(alpha_weights, torch.Tensor):
        alpha_weights = alpha_weights.detach().cpu().numpy()
    
    # åˆ›å»ºæ¡å½¢å›¾
    fig, ax = plt.subplots(figsize=(8, 6))
    bars = ax.bar(layer_names, alpha_weights)
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Layers')
    ax.set_ylabel('Weight Values')
    ax.set_title(title)
    ax.set_ylim(0, 1)
    
    # åœ¨æ¯ä¸ªæ¡å½¢ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bar, weight in zip(bars, alpha_weights):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{weight:.3f}',
                ha='center', va='bottom')
    
    plt.tight_layout()
    _finalize_figure(fig, title, save_path)


def plot_training_curve(train_losses, train_accuracies, val_accuracies=None, title="Training Curve", val_epochs=None, save_path=None):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    
    Args:
        train_losses: è®­ç»ƒæŸå¤±åˆ—è¡¨
        train_accuracies: è®­ç»ƒå‡†ç¡®ç‡åˆ—è¡¨
        val_accuracies: éªŒè¯å‡†ç¡®ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
    """
    epochs = range(1, len(train_losses) + 1)
    
    fig, ax1 = plt.subplots(figsize=(10, 6))
    
    # ç»˜åˆ¶è®­ç»ƒæŸå¤±
    color = 'tab:red'
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss', color=color)
    ax1.plot(epochs, train_losses, color=color, label='Train Loss')
    ax1.tick_params(axis='y', labelcolor=color)
    
    # åˆ›å»ºç¬¬äºŒä¸ªyè½´ç”¨äºå‡†ç¡®ç‡
    ax2 = ax1.twinx()
    color = 'tab:blue'
    ax2.set_ylabel('Accuracy', color=color)
    ax2.plot(epochs, train_accuracies, color=color, label='Train Accuracy')
    
    # ç»˜åˆ¶éªŒè¯å‡†ç¡®ç‡ï¼ˆå¦‚æœæä¾›ï¼‰
    if val_accuracies is not None and len(val_accuracies) > 0:
        val_x = val_epochs if val_epochs is not None else list(range(10, len(train_losses) + 1, 10))
        ax2.plot(val_x, val_accuracies, color='tab:green', label='Val Accuracy')
    
    ax2.tick_params(axis='y', labelcolor=color)
    
    # æ·»åŠ å›¾ä¾‹
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    
    plt.title(title)
    plt.tight_layout()
    _finalize_figure(fig, title, save_path)


def plot_epoch_accuracy(epoch_accuracies, title="Epoch Average Accuracy", save_path=None):
    """
    ç»˜åˆ¶epochå¹³å‡å‡†ç¡®ç‡æ›²çº¿
    
    Args:
        epoch_accuracies: epochå¹³å‡å‡†ç¡®ç‡åˆ—è¡¨
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    epochs = range(1, len(epoch_accuracies) + 1)
    
    fig = plt.figure(figsize=(10, 6))
    plt.plot(epochs, epoch_accuracies, 'b-', linewidth=2, marker='o', markersize=6, label='Epoch Accuracy')
    
    # æ·»åŠ ç½‘æ ¼
    plt.grid(True, alpha=0.3)
    
    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    plt.xlabel('Epoch')
    plt.ylabel('Average Accuracy')
    plt.title(title)
    plt.legend()
    
    # è®¾ç½®yè½´èŒƒå›´
    plt.ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡æ³¨ï¼ˆæ¯5ä¸ªepochæ ‡æ³¨ä¸€æ¬¡ï¼‰
    for i in range(0, len(epoch_accuracies), 5):
        plt.annotate(f'{epoch_accuracies[i]:.3f}', 
                    (epochs[i], epoch_accuracies[i]),
                    textcoords="offset points", 
                    xytext=(0,10), 
                    ha='center')
    
    plt.tight_layout()
    _finalize_figure(fig, title, save_path)


def plot_epoch_statistics(epoch_means, epoch_stds=None, title="Epoch Statistics", save_path=None):
    """
    ç»˜åˆ¶epochç»Ÿè®¡ä¿¡æ¯ï¼ˆå¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼‰
    
    Args:
        epoch_means: epochå¹³å‡å‡†ç¡®ç‡åˆ—è¡¨
        epoch_stds: epochæ ‡å‡†å·®åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    epochs = range(1, len(epoch_means) + 1)
    
    fig = plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶å¹³å‡å‡†ç¡®ç‡
    plt.plot(epochs, epoch_means, 'b-', linewidth=2, marker='o', markersize=6, label='Mean Accuracy')
    
    # å¦‚æœæä¾›äº†æ ‡å‡†å·®ï¼Œç»˜åˆ¶è¯¯å·®å¸¦
    if epoch_stds is not None:
        epoch_means_arr = np.array(epoch_means)
        epoch_stds_arr = np.array(epoch_stds)
        plt.fill_between(epochs, 
                        epoch_means_arr - epoch_stds_arr, 
                        epoch_means_arr + epoch_stds_arr, 
                        alpha=0.2, color='blue', label='Â±1 Std Dev')
    
    # æ·»åŠ ç½‘æ ¼
    plt.grid(True, alpha=0.3)
    
    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(title)
    plt.legend()
    
    # è®¾ç½®yè½´èŒƒå›´
    plt.ylim(0, 1)
    
    plt.tight_layout()
    
    _finalize_figure(fig, title, save_path)


def plot_accuracy_comparison(train_accuracies, val_accuracies=None, test_accuracies=None, 
                           title="Accuracy Comparison", save_path=None, val_epochs=None, test_epochs=None):
    """
    æ¯”è¾ƒè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•å‡†ç¡®ç‡
    
    Args:
        train_accuracies: è®­ç»ƒå‡†ç¡®ç‡åˆ—è¡¨
        val_accuracies: éªŒè¯å‡†ç¡®ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        test_accuracies: æµ‹è¯•å‡†ç¡®ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    epochs = range(1, len(train_accuracies) + 1)
    
    fig = plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶è®­ç»ƒå‡†ç¡®ç‡
    plt.plot(epochs, train_accuracies, 'b-', linewidth=2, marker='o', 
             markersize=4, label='Train Accuracy')
    
    # ç»˜åˆ¶éªŒè¯å‡†ç¡®ç‡
    if val_accuracies is not None:
        if val_epochs is None:
            if len(val_accuracies) == len(train_accuracies):
                val_epochs = range(1, len(val_accuracies) + 1)
            else:
                val_epochs = list(range(10, len(train_accuracies) + 1, 10))
        plt.plot(val_epochs, val_accuracies, 'g-', linewidth=2, marker='s', 
                 markersize=4, label='Validation Accuracy')
    
    # ç»˜åˆ¶æµ‹è¯•å‡†ç¡®ç‡
    if test_accuracies is not None:
        if test_epochs is None:
            test_epochs = range(1, len(test_accuracies) + 1)
        plt.plot(test_epochs, test_accuracies, 'r-', linewidth=2, marker='^', 
                 markersize=4, label='Test Accuracy')
    
    # æ·»åŠ ç½‘æ ¼
    plt.grid(True, alpha=0.3)
    
    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(title)
    plt.legend()
    
    # è®¾ç½®yè½´èŒƒå›´
    plt.ylim(0, 1)
    
    plt.tight_layout()
    
    _finalize_figure(fig, title, save_path)


def plot_accuracy_heatmap(accuracy_matrix, class_names=None, metric_names=None, title="Accuracy Heatmap", save_path=None):
    """
    ç»˜åˆ¶å‡†ç¡®ç‡çƒ­åŠ›å›¾ï¼ˆç”¨äºåˆ†æä¸åŒç±»åˆ«æˆ–æ¡ä»¶ä¸‹çš„å‡†ç¡®ç‡ï¼‰
    
    Args:
        accuracy_matrix: å‡†ç¡®ç‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º[n_conditions, n_metrics]
        class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨ä½œè¡Œæ ‡ç­¾ï¼‰
        metric_names: æŒ‡æ ‡åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨ä½œåˆ—æ ‡ç­¾ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    fig = plt.figure(figsize=(12, 8))
    
    # æ£€æµ‹æ•°æ®ç±»å‹å¹¶è®¾ç½®åˆé€‚çš„é¢œè‰²æ˜ å°„å’ŒèŒƒå›´
    matrix = np.array(accuracy_matrix)
    
    # å¦‚æœæ•°æ®åŒ…å«æ ‡å‡†å·®ï¼ˆé€šå¸¸åœ¨ç¬¬ä¸‰åˆ—ï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
    if matrix.shape[1] >= 3:
        # åˆ†åˆ«å¤„ç†å‡†ç¡®ç‡åˆ—ï¼ˆ0,1ï¼‰å’Œæ ‡å‡†å·®åˆ—ï¼ˆ2+ï¼‰
        acc_data = matrix[:, :2]  # å‡†ç¡®ç‡æ•°æ®
        std_data = matrix[:, 2:]  # æ ‡å‡†å·®æ•°æ®
        
        # æ ‡å‡†åŒ–å¤„ç†ï¼šå°†æ ‡å‡†å·®ç¼©æ”¾åˆ°0-1èŒƒå›´ä»¥ä¾¿å¯è§†åŒ–
        if std_data.size > 0:
            std_normalized = (std_data - std_data.min()) / (std_data.max() - std_data.min() + 1e-8)
            # é‡æ–°ç»„åˆæ•°æ®
            display_matrix = np.concatenate([acc_data, std_normalized], axis=1)
        else:
            display_matrix = acc_data
    else:
        display_matrix = matrix
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    im = plt.imshow(display_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)
    
    # è®¾ç½®è¡Œæ ‡ç­¾ï¼ˆæ¡ä»¶/ç±»åˆ«ï¼‰
    if class_names is not None:
        plt.yticks(range(len(class_names)), class_names, fontproperties=FontProperties(family=_selected_font))
    
    # è®¾ç½®åˆ—æ ‡ç­¾ï¼ˆæŒ‡æ ‡ï¼‰
    if metric_names is not None:
        plt.xticks(range(len(metric_names)), metric_names, rotation=45, ha='right', fontproperties=FontProperties(family=_selected_font))
    else:
        plt.xlabel('Metrics')
    
    plt.ylabel('Epochs/Conditions')
    plt.title(title)
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im)
    if matrix.shape[1] >= 3:
        cbar.set_label('Normalized Values (Accuracy: 0-1, Std: normalized)')
    else:
        cbar.set_label('Accuracy')
    
    # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºåŸå§‹æ•°å€¼
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[1]):
            # æ˜¾ç¤ºåŸå§‹å€¼ï¼Œä¸æ˜¯æ ‡å‡†åŒ–åçš„å€¼
            value = matrix[i, j]
            if j < 2:  # å‡†ç¡®ç‡åˆ—
                text_str = f'{value:.3f}'
            else:  # æ ‡å‡†å·®åˆ—
                text_str = f'{value:.4f}'
            
            # æ ¹æ®èƒŒæ™¯é¢œè‰²é€‰æ‹©æ–‡å­—é¢œè‰²
            text_color = "white" if display_matrix[i, j] < 0.5 else "black"
            plt.text(j, i, text_str, ha="center", va="center", color=text_color, fontsize=9)
    
    plt.tight_layout()
    
    _finalize_figure(fig, title, save_path)


def plot_val_accuracy_curve(val_accuracies, title="Validation Accuracy Curve", val_epochs=None, save_path=None):
    if isinstance(val_accuracies, torch.Tensor):
        val_accuracies = val_accuracies.detach().cpu().numpy()
    if val_epochs is None:
        val_epochs = range(1, len(val_accuracies) + 1)
    fig = plt.figure(figsize=(10, 6))
    plt.plot(val_epochs, val_accuracies, 'g-', linewidth=2, marker='s', markersize=6, label='Validation Accuracy')
    plt.grid(True, alpha=0.3)
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(title)
    plt.legend()
    plt.ylim(0, 1)
    plt.tight_layout()
    _finalize_figure(fig, title, save_path)


def plot_separation_ratio_curve(sep_ratios, sep_epochs=None, title="Separation Ratio Curve", save_path=None):
    if isinstance(sep_ratios, torch.Tensor):
        sep_ratios = sep_ratios.detach().cpu().numpy()
    if sep_epochs is None:
        sep_epochs = list(range(5, 5 * len(sep_ratios) + 1, 5))
    fig = plt.figure(figsize=(10, 6))
    plt.plot(sep_epochs, sep_ratios, 'm-', linewidth=2, marker='d', markersize=6, label='Separation Ratio')
    plt.grid(True, alpha=0.3)
    plt.xlabel('Epoch')
    plt.ylabel('Separation Ratio')
    plt.title(title)
    plt.legend()
    plt.tight_layout()
    _finalize_figure(fig, title, save_path)


# =============================================================================
# T-SNE å¯è§†åŒ–æ¨¡å—
# =============================================================================

def plot_tsne_embeddings(
    features: Union[torch.Tensor, np.ndarray],
    labels: Union[torch.Tensor, np.ndarray],
    epoch: int,
    n_way: int = 5,
    domain_labels: Optional[Union[torch.Tensor, np.ndarray]] = None,
    prototypes: Optional[Union[torch.Tensor, np.ndarray]] = None,
    title: Optional[str] = None,
    save_dir: str = "figures/T-SNE",
    perplexity: float = 30.0,
    max_iter: int = 1000,
    random_state: int = 42,
    class_names: Optional[List[str]] = None,
    domain_names: Optional[List[str]] = None,
    figsize: Tuple[int, int] = (12, 10),
    init_embedding: Optional[Union[torch.Tensor, np.ndarray]] = None,
    pca_dim: int = 50,
    high_dim_metrics: Optional[Dict[str, float]] = None,
) -> Dict[str, float]:
    """
    ä½¿ç”¨ T-SNE å¯è§†åŒ–ç‰¹å¾åµŒå…¥çš„èšç±»ç¨‹åº¦
    
    éµå¾ª sklearn 1.7+ æœ€ä½³å®è·µ:
    - é«˜ç»´ç‰¹å¾å…ˆç”¨ PCA é™è‡³ pca_dim ç»´ï¼ˆå®˜æ–¹æ¨èï¼‰
    - ä½¿ç”¨ init='pca' æé«˜ç¨³å®šæ€§
    - ä½¿ç”¨ learning_rate='auto' è‡ªé€‚åº”å­¦ä¹ ç‡
    
    Args:
        features: ç‰¹å¾çŸ©é˜µ ``[N, D]``ï¼ŒNä¸ºæ ·æœ¬æ•°ï¼ŒDä¸ºç‰¹å¾ç»´åº¦
        labels: ç±»åˆ«æ ‡ç­¾ ``[N]``ï¼ŒèŒƒå›´ ``[0, n_way-1]``
        epoch: å½“å‰è®­ç»ƒè½®æ•°ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        n_way: ç±»åˆ«æ•°é‡
        domain_labels: åŸŸæ ‡ç­¾ ``[N]``ï¼ˆå¯é€‰ï¼Œç”¨äºåŒºåˆ†ä¸åŒåŸŸï¼‰
        prototypes: åŸå‹å‘é‡ ``[n_way, D]``ï¼ˆå¯é€‰ï¼Œå°†åŸå‹æŠ•å½±åˆ°T-SNEç©ºé—´ï¼‰
        title: å›¾è¡¨æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
        save_dir: ä¿å­˜ç›®å½•
        perplexity: T-SNEå›°æƒ‘åº¦å‚æ•°ï¼Œå»ºè®®å€¼5-50ï¼Œæ ·æœ¬å°‘æ—¶ç”¨è¾ƒå°å€¼
        max_iter: T-SNEæœ€å¤§è¿­ä»£æ¬¡æ•° (sklearn 1.5+ ä½¿ç”¨ max_iter)
        random_state: éšæœºç§å­
        class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        domain_names: åŸŸåç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        figsize: å›¾åƒå°ºå¯¸
        init_embedding: ä¸Šä¸€æ¬¡çš„åµŒå…¥åæ ‡ [N, 2]ï¼Œç”¨äºä¿æŒè§†è§‰ä¸€è‡´æ€§ (Warm Start)
        pca_dim: PCAé¢„é™ç»´ç›®æ ‡ç»´åº¦ï¼ˆsklearnå®˜æ–¹å»ºè®®50ç»´ï¼‰
        
    Returns:
        metrics: åŒ…å«èšç±»åº¦é‡æŒ‡æ ‡çš„å­—å…¸
            - silhouette_score: è½®å»“ç³»æ•° [-1, 1]ï¼Œè¶Šå¤§è¶Šå¥½
            - intra_class_dist: ç±»å†…å¹³å‡è·ç¦»ï¼Œè¶Šå°è¶Šå¥½
            - inter_class_dist: ç±»é—´å¹³å‡è·ç¦»ï¼Œè¶Šå¤§è¶Šå¥½
            - cluster_ratio: inter/intraæ¯”å€¼ï¼Œè¶Šå¤§èšç±»æ•ˆæœè¶Šå¥½
    """
    from sklearn.decomposition import PCA
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(features, torch.Tensor):
        features = features.detach().cpu().numpy()
    if isinstance(labels, torch.Tensor):
        labels = labels.detach().cpu().numpy()
    if domain_labels is not None and isinstance(domain_labels, torch.Tensor):
        domain_labels = domain_labels.detach().cpu().numpy()
    if prototypes is not None and isinstance(prototypes, torch.Tensor):
        prototypes = prototypes.detach().cpu().numpy()
    if init_embedding is not None and isinstance(init_embedding, torch.Tensor):
        init_embedding = init_embedding.detach().cpu().numpy()
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)
    
    # åˆå¹¶ç‰¹å¾å’ŒåŸå‹ï¼ˆå¦‚æœæä¾›ï¼‰
    if prototypes is not None:
        all_features = np.vstack([features, prototypes])
        n_samples = features.shape[0]
    else:
        all_features = features
        n_samples = features.shape[0]
    
    # ===== sklearnå®˜æ–¹æœ€ä½³å®è·µï¼šé«˜ç»´ç‰¹å¾å…ˆç”¨PCAé™ç»´ =====
    # "It is highly recommended to use another dimensionality reduction method 
    #  (e.g. PCA for dense data) to reduce the number of dimensions to a 
    #  reasonable amount (e.g. 50) if the number of features is very high."
    n_features = all_features.shape[1]
    if n_features > pca_dim:
        # ç¡®ä¿PCAç»„ä»¶æ•°ä¸è¶…è¿‡æ ·æœ¬æ•°å’Œç‰¹å¾æ•°
        n_pca_components = min(pca_dim, all_features.shape[0] - 1, n_features)
        pca = PCA(n_components=n_pca_components, random_state=random_state)
        all_features = pca.fit_transform(all_features)
    
    effective_perplexity = min(perplexity, (all_features.shape[0] - 1) / 3)
    effective_perplexity = max(5.0, effective_perplexity)  # æœ€å°å€¼ä¸º5
    
    # æ‰§è¡ŒT-SNEé™ç»´ (sklearn 1.7+ API)
    tsne = TSNE(
        n_components=2,
        perplexity=effective_perplexity,
        max_iter=max_iter,          # sklearn 1.5+ å‚æ•°å
        random_state=random_state,   # ç”¨æˆ·æŒ‡å®šå›ºå®šéšæœºç§å­
        init='pca',                  # ç”¨æˆ·å¼ºåˆ¶æŒ‡å®š init='pca'
        learning_rate='auto',        # sklearn 1.2+ é»˜è®¤å€¼ï¼Œè‡ªé€‚åº”
        n_iter_without_progress=300, # æ—©åœå‚æ•°
        method='barnes_hut',         # O(NlogN) å¤æ‚åº¦ï¼Œé€‚åˆå¤§æ•°æ®
        angle=0.5,                   # Barnes-Hut ç²¾åº¦-é€Ÿåº¦æƒè¡¡
    )
    embeddings_2d = tsne.fit_transform(all_features)
    
    # åˆ†ç¦»æ ·æœ¬åµŒå…¥å’ŒåŸå‹åµŒå…¥
    sample_embeddings = embeddings_2d[:n_samples]
    proto_embeddings = embeddings_2d[n_samples:] if prototypes is not None else None
    
    # è®¡ç®—èšç±»åº¦é‡æŒ‡æ ‡
    # è‹¥æä¾›äº†é«˜ç»´ç©ºé—´ä¸Šçš„é¢„è®¡ç®—æŒ‡æ ‡ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™é€€å›åˆ°åœ¨2D T-SNEç©ºé—´ä¸Šä¼°è®¡
    if high_dim_metrics is not None:
        metrics = high_dim_metrics
    else:
        metrics = _compute_clustering_metrics(sample_embeddings, labels, n_way)
    
    # è®¾ç½®é¢œè‰²æ˜ å°„
    cmap = plt.cm.get_cmap('tab10', n_way)
    colors = [cmap(i) for i in range(n_way)]
    
    # åˆ›å»ºå›¾å½¢
    if domain_labels is not None:
        fig, axes = plt.subplots(1, 2, figsize=(figsize[0] * 1.5, figsize[1]))
        ax_class, ax_domain = axes
    else:
        fig, ax_class = plt.subplots(1, 1, figsize=figsize)
        ax_domain = None
    
    # === æŒ‰ç±»åˆ«ç€è‰²çš„æ•£ç‚¹å›¾ ===
    for c in range(n_way):
        mask = labels == c
        label_name = class_names[c] if class_names else f"ç±»åˆ« {c}"
        ax_class.scatter(
            sample_embeddings[mask, 0],
            sample_embeddings[mask, 1],
            c=[colors[c]],
            label=label_name,
            alpha=0.7,
            s=50,
            edgecolors='white',
            linewidths=0.5
        )
    
    # ç»˜åˆ¶åŸå‹ï¼ˆå¦‚æœæä¾›ï¼‰
    if proto_embeddings is not None:
        for c in range(n_way):
            ax_class.scatter(
                proto_embeddings[c, 0],
                proto_embeddings[c, 1],
                c=[colors[c]],
                marker='*',
                s=400,
                edgecolors='black',
                linewidths=2,
                zorder=10,
                label=f"åŸå‹ {c}" if c == 0 else None
            )
            # æ·»åŠ åŸå‹æ ‡æ³¨
            ax_class.annotate(
                f'P{c}',
                (proto_embeddings[c, 0], proto_embeddings[c, 1]),
                fontsize=10,
                fontweight='bold',
                ha='center',
                va='bottom',
                xytext=(0, 8),
                textcoords='offset points'
            )
    
    ax_class.set_xlabel('T-SNE ç»´åº¦ 1', fontsize=12)
    ax_class.set_ylabel('T-SNE ç»´åº¦ 2', fontsize=12)
    ax_class.legend(loc='best', fontsize=9, framealpha=0.9)
    ax_class.grid(True, alpha=0.3)
    ax_class.set_title(f'æŒ‰ç±»åˆ«ç€è‰² (Epoch {epoch})', fontsize=14)
    
    # æ·»åŠ èšç±»æŒ‡æ ‡æ–‡æœ¬æ¡†
    textstr = '\n'.join([
        f'è½®å»“ç³»æ•°: {metrics["silhouette_score"]:.3f}',
        f'ç±»å†…è·ç¦»: {metrics["intra_class_dist"]:.3f}',
        f'ç±»é—´è·ç¦»: {metrics["inter_class_dist"]:.3f}',
        f'èšç±»æ¯”: {metrics["cluster_ratio"]:.3f}'
    ])
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    ax_class.text(
        0.02, 0.98, textstr,
        transform=ax_class.transAxes,
        fontsize=10,
        verticalalignment='top',
        bbox=props,
        fontproperties=FontProperties(family=_selected_font)
    )
    
    # === æŒ‰åŸŸç€è‰²çš„æ•£ç‚¹å›¾ï¼ˆå¦‚æœæä¾›åŸŸæ ‡ç­¾ï¼‰===
    if ax_domain is not None and domain_labels is not None:
        unique_domains = np.unique(domain_labels)
        domain_cmap = plt.cm.get_cmap('Set2', len(unique_domains))
        
        # å®šä¹‰åŸŸçš„æ ‡è®°æ ·å¼
        markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p']
        
        for i, d in enumerate(unique_domains):
            mask = domain_labels == d
            domain_name = domain_names[d] if domain_names and d < len(domain_names) else f"åŸŸ {d}"
            ax_domain.scatter(
                sample_embeddings[mask, 0],
                sample_embeddings[mask, 1],
                c=[domain_cmap(i)],
                marker=markers[i % len(markers)],
                label=domain_name,
                alpha=0.7,
                s=50,
                edgecolors='white',
                linewidths=0.5
            )
        
        ax_domain.set_xlabel('T-SNE ç»´åº¦ 1', fontsize=12)
        ax_domain.set_ylabel('T-SNE ç»´åº¦ 2', fontsize=12)
        ax_domain.legend(loc='best', fontsize=9, framealpha=0.9)
        ax_domain.grid(True, alpha=0.3)
        ax_domain.set_title(f'æŒ‰åŸŸç€è‰² (Epoch {epoch})', fontsize=14)
    
    # è®¾ç½®æ€»æ ‡é¢˜
    if title is None:
        title = f"T-SNE ç‰¹å¾å¯è§†åŒ– - Epoch {epoch}"
    fig.suptitle(title, fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f"tsne_epoch_{epoch:03d}.png")
    fig.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close(fig)
    
    print(f"  ğŸ“Š T-SNEå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    print(f"     èšç±»æŒ‡æ ‡ - è½®å»“ç³»æ•°: {metrics['silhouette_score']:.4f}, èšç±»æ¯”: {metrics['cluster_ratio']:.4f}")
    
    return metrics, embeddings_2d


def _compute_clustering_metrics(
    embeddings: np.ndarray,
    labels: np.ndarray,
    n_way: int
) -> Dict[str, float]:
    """
    è®¡ç®—èšç±»è´¨é‡åº¦é‡æŒ‡æ ‡
    
    Args:
        embeddings: T-SNEé™ç»´åçš„2Dåæ ‡ ``[N, 2]``
        labels: ç±»åˆ«æ ‡ç­¾ ``[N]``
        n_way: ç±»åˆ«æ•°é‡
        
    Returns:
        metrics: èšç±»åº¦é‡æŒ‡æ ‡å­—å…¸
    """
    from sklearn.metrics import silhouette_score as sklearn_silhouette
    
    metrics = {}
    
    # 1. è½®å»“ç³»æ•° (Silhouette Score)
    try:
        if len(np.unique(labels)) > 1:
            metrics['silhouette_score'] = sklearn_silhouette(embeddings, labels)
        else:
            metrics['silhouette_score'] = 0.0
    except Exception:
        metrics['silhouette_score'] = 0.0
    
    # 2. ç±»å†…å¹³å‡è·ç¦» (Intra-class distance)
    intra_dists = []
    class_centers = []
    for c in range(n_way):
        mask = labels == c
        if mask.sum() > 1:
            class_points = embeddings[mask]
            center = class_points.mean(axis=0)
            class_centers.append(center)
            dists = np.sqrt(((class_points - center) ** 2).sum(axis=1))
            intra_dists.append(dists.mean())
        elif mask.sum() == 1:
            class_centers.append(embeddings[mask][0])
            intra_dists.append(0.0)
    
    metrics['intra_class_dist'] = np.mean(intra_dists) if intra_dists else 0.0
    
    # 3. ç±»é—´å¹³å‡è·ç¦» (Inter-class distance)
    if len(class_centers) > 1:
        class_centers = np.array(class_centers)
        inter_dists = []
        for i in range(len(class_centers)):
            for j in range(i + 1, len(class_centers)):
                dist = np.sqrt(((class_centers[i] - class_centers[j]) ** 2).sum())
                inter_dists.append(dist)
        metrics['inter_class_dist'] = np.mean(inter_dists)
    else:
        metrics['inter_class_dist'] = 0.0
    
    # 4. èšç±»æ¯” (Cluster Ratio = inter/intra)
    if metrics['intra_class_dist'] > 1e-6:
        metrics['cluster_ratio'] = metrics['inter_class_dist'] / metrics['intra_class_dist']
    else:
        metrics['cluster_ratio'] = float('inf') if metrics['inter_class_dist'] > 0 else 0.0
    
    return metrics


def plot_tsne_evolution(
    metrics_history: List[Dict[str, float]],
    epochs: List[int],
    save_dir: str = "figures/T-SNE",
    title: str = "T-SNE èšç±»æŒ‡æ ‡æ¼”åŒ–"
) -> None:
    """
    ç»˜åˆ¶T-SNEèšç±»æŒ‡æ ‡éšè®­ç»ƒçš„æ¼”åŒ–æ›²çº¿
    
    Args:
        metrics_history: æ¯ä¸ªepochçš„èšç±»æŒ‡æ ‡åˆ—è¡¨
        epochs: å¯¹åº”çš„epochåˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
        title: å›¾è¡¨æ ‡é¢˜
    """
    os.makedirs(save_dir, exist_ok=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # æå–å„æŒ‡æ ‡
    silhouette = [m['silhouette_score'] for m in metrics_history]
    intra_dist = [m['intra_class_dist'] for m in metrics_history]
    inter_dist = [m['inter_class_dist'] for m in metrics_history]
    cluster_ratio = [m['cluster_ratio'] for m in metrics_history]
    
    # è½®å»“ç³»æ•°
    axes[0, 0].plot(epochs, silhouette, 'b-o', linewidth=2, markersize=6)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('è½®å»“ç³»æ•°')
    axes[0, 0].set_title('è½®å»“ç³»æ•° (è¶Šå¤§è¶Šå¥½)')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)
    
    # ç±»å†…è·ç¦»
    axes[0, 1].plot(epochs, intra_dist, 'r-s', linewidth=2, markersize=6)
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('ç±»å†…å¹³å‡è·ç¦»')
    axes[0, 1].set_title('ç±»å†…è·ç¦» (è¶Šå°è¶Šå¥½)')
    axes[0, 1].grid(True, alpha=0.3)
    
    # ç±»é—´è·ç¦»
    axes[1, 0].plot(epochs, inter_dist, 'g-^', linewidth=2, markersize=6)
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('ç±»é—´å¹³å‡è·ç¦»')
    axes[1, 0].set_title('ç±»é—´è·ç¦» (è¶Šå¤§è¶Šå¥½)')
    axes[1, 0].grid(True, alpha=0.3)
    
    # èšç±»æ¯”
    axes[1, 1].plot(epochs, cluster_ratio, 'm-d', linewidth=2, markersize=6)
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('èšç±»æ¯” (Inter/Intra)')
    axes[1, 1].set_title('èšç±»æ¯” (è¶Šå¤§è¶Šå¥½)')
    axes[1, 1].grid(True, alpha=0.3)
    
    fig.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    save_path = os.path.join(save_dir, "tsne_metrics_evolution.png")
    fig.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close(fig)
    
    print(f"  ğŸ“ˆ T-SNEèšç±»æŒ‡æ ‡æ¼”åŒ–å›¾å·²ä¿å­˜: {save_path}")


def plot_leakindex_curve(
    leakindex_history: List[float],
    leakintensity_history: List[float],
    epochs: Optional[List[int]] = None,
    title: str = "LeakIndex æ¼”åŒ–æ›²çº¿",
    save_path: Optional[str] = None
) -> None:
    """
    ç»˜åˆ¶ LeakIndex å’Œ LeakIntensity æ¼”åŒ–æ›²çº¿ï¼ˆå•ç‹¬ subplotï¼‰
    
    LeakIndex = CDSC - CDDC (å¸¦ç¬¦å·)
    - LeakIndex > 0: åŸŸæ”¯åœ¨æŒ‰ç±»åˆ«èšç±» â†’ è¯­ä¹‰æ³„éœ²
    - LeakIndex â‰ˆ 0: åŸŸæ”¯ä¸æºå¸¦ç±»åˆ«ä¿¡æ¯ â†’ ç†æƒ³çŠ¶æ€
    - LeakIndex < 0: åŸŸæ”¯è¿‡åº¦æŠ‘åˆ¶åŒç±»ç›¸ä¼¼åº¦
    
    LeakIntensity = max(0, LeakIndex) (ä»…æ­£å€¼éƒ¨åˆ†)
    - ç”¨äºç›‘æ§æ³„éœ²å¼ºåº¦çš„ç»å¯¹å€¼
    
    Args:
        leakindex_history: LeakIndex å†å²è®°å½•ï¼ˆå¸¦ç¬¦å·ï¼‰
        leakintensity_history: LeakIntensity å†å²è®°å½•ï¼ˆä»…æ­£å€¼ï¼‰
        epochs: epoch åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä» 1 å¼€å§‹ï¼‰
        title: å›¾è¡¨æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Examples:
        >>> plot_leakindex_curve([0.1, 0.2, -0.1], [0.1, 0.2, 0.0])
    """
    # è½¬æ¢ä¸º numpy æ•°ç»„
    if isinstance(leakindex_history, torch.Tensor):
        leakindex_history = leakindex_history.detach().cpu().numpy()
    if isinstance(leakintensity_history, torch.Tensor):
        leakintensity_history = leakintensity_history.detach().cpu().numpy()
    
    leakindex_arr = np.array(leakindex_history)
    leakintensity_arr = np.array(leakintensity_history)
    
    # ç”Ÿæˆ epoch åˆ—è¡¨
    if epochs is None:
        epochs = list(range(1, len(leakindex_arr) + 1))
    
    # åˆ›å»º 1x2 subplot
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # === å·¦å›¾: LeakIndex (å¸¦ç¬¦å·) ===
    ax_leak = axes[0]
    ax_leak.plot(epochs, leakindex_arr, 'b-o', linewidth=2, markersize=6, label='LeakIndex')
    ax_leak.axhline(y=0, color='r', linestyle='--', linewidth=1.5, alpha=0.7, label='ç†æƒ³å€¼ (LeakIndex=0)')
    ax_leak.fill_between(epochs, 0, leakindex_arr, where=(leakindex_arr > 0), 
                         color='red', alpha=0.2, label='æ³„éœ²åŒºåŸŸ (>0)')
    ax_leak.fill_between(epochs, 0, leakindex_arr, where=(leakindex_arr < 0), 
                         color='green', alpha=0.2, label='æŠ‘åˆ¶åŒºåŸŸ (<0)')
    
    ax_leak.set_xlabel('Epoch', fontsize=12)
    ax_leak.set_ylabel('LeakIndex (CDSC - CDDC)', fontsize=12)
    ax_leak.set_title('LeakIndex æ¼”åŒ– (å¸¦ç¬¦å·)', fontsize=14, fontweight='bold')
    ax_leak.legend(loc='best', fontsize=10, framealpha=0.9)
    ax_leak.grid(True, alpha=0.3)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
    mean_leak = np.mean(leakindex_arr)
    std_leak = np.std(leakindex_arr)
    max_leak = np.max(leakindex_arr)
    min_leak = np.min(leakindex_arr)
    
    textstr_leak = '\n'.join([
        f'å‡å€¼: {mean_leak:.4f}',
        f'æ ‡å‡†å·®: {std_leak:.4f}',
        f'æœ€å¤§å€¼: {max_leak:.4f}',
        f'æœ€å°å€¼: {min_leak:.4f}'
    ])
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    ax_leak.text(
        0.02, 0.98, textstr_leak,
        transform=ax_leak.transAxes,
        fontsize=10,
        verticalalignment='top',
        bbox=props,
        fontproperties=FontProperties(family=_selected_font)
    )
    
    # === å³å›¾: LeakIntensity (ä»…æ­£å€¼) ===
    ax_intensity = axes[1]
    ax_intensity.plot(epochs, leakintensity_arr, 'r-s', linewidth=2, markersize=6, label='LeakIntensity')
    ax_intensity.fill_between(epochs, 0, leakintensity_arr, color='red', alpha=0.2)
    ax_intensity.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)
    
    ax_intensity.set_xlabel('Epoch', fontsize=12)
    ax_intensity.set_ylabel('LeakIntensity (max(0, LeakIndex))', fontsize=12)
    ax_intensity.set_title('LeakIntensity æ¼”åŒ– (ä»…æ­£å€¼)', fontsize=14, fontweight='bold')
    ax_intensity.legend(loc='best', fontsize=10, framealpha=0.9)
    ax_intensity.grid(True, alpha=0.3)
    ax_intensity.set_ylim(bottom=0)  # å¼ºåˆ¶ y è½´ä» 0 å¼€å§‹
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
    mean_intensity = np.mean(leakintensity_arr)
    std_intensity = np.std(leakintensity_arr)
    max_intensity = np.max(leakintensity_arr)
    
    textstr_intensity = '\n'.join([
        f'å‡å€¼: {mean_intensity:.4f}',
        f'æ ‡å‡†å·®: {std_intensity:.4f}',
        f'æœ€å¤§å€¼: {max_intensity:.4f}',
        f'éé›¶æ¯”ä¾‹: {(leakintensity_arr > 1e-6).sum() / len(leakintensity_arr):.2%}'
    ])
    ax_intensity.text(
        0.02, 0.98, textstr_intensity,
        transform=ax_intensity.transAxes,
        fontsize=10,
        verticalalignment='top',
        bbox=props,
        fontproperties=FontProperties(family=_selected_font)
    )
    
    # è®¾ç½®æ€»æ ‡é¢˜
    fig.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜æˆ–æ˜¾ç¤º
    _finalize_figure(fig, title, save_path)
    
    print(f"  ğŸ“Š LeakIndex æ›²çº¿å·²ä¿å­˜: {save_path if save_path else _default_save_path(title)}")